{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Created some day.\n",
    "@authors:  salmon, gramfort, vernade\n",
    "\"\"\"\n",
    "from functools import partial  # useful for weighted distances\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn import metrics\n",
    "from scipy import stats  # to use scipy.stats.mode\n",
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from TP2.tpknnsource import (rand_gauss, rand_bi_gauss, rand_tri_gauss,\n",
    "                             rand_checkers, rand_clown, plot_2d, ErrorCurve,\n",
    "                             frontiere_new, LOOCurve)\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "\n",
    "plt.close('all')\n",
    "rc('font', **{'family': 'sans-serif', 'sans-serif': ['Computer Modern Roman']})\n",
    "params = {'axes.labelsize': 12,\n",
    "          'font.size': 16,\n",
    "          'legend.fontsize': 16,\n",
    "          'text.usetex': False,\n",
    "          'figure.figsize': (8, 6)}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set_style(\"white\")\n",
    "sns.axes_style()\n",
    "\n",
    "############################################################################\n",
    "#     Data Generation: example\n",
    "############################################################################\n",
    "\n",
    "# Q1 : Take Mean, Median ...\n",
    "\n",
    "np.random.seed(42)  # fix seed globally\n",
    "\n",
    "n = 100\n",
    "mu = [1., 1.]\n",
    "sigma = [1., 1.]\n",
    "rand_gauss(n, mu, sigma)\n",
    "\n",
    "n1 = 20\n",
    "n2 = 20\n",
    "mu1 = [1., 1.]\n",
    "mu2 = [-1., -1.]\n",
    "sigma1 = [0.9, 0.9]\n",
    "sigma2 = [0.9, 0.9]\n",
    "X1, y1 = rand_bi_gauss(n1, n2, mu1, mu2, sigma1, sigma2)\n",
    "\n",
    "n1 = 50\n",
    "n2 = 50\n",
    "n3 = 50\n",
    "mu1 = [1., 1.]\n",
    "mu2 = [-1., -1.]\n",
    "mu3 = [1., -1.]\n",
    "sigma1 = [0.9, 0.9]\n",
    "sigma2 = [0.9, 0.9]\n",
    "sigma3 = [0.9, 0.9]\n",
    "X2, y2 = rand_tri_gauss(n1, n2, n3, mu1, mu2, mu3, sigma1, sigma2, sigma3)\n",
    "\n",
    "n1 = 50\n",
    "n2 = 50\n",
    "sigma1 = 1.\n",
    "sigma2 = 5.\n",
    "X3, y3 = rand_clown(n1, n2, sigma1, sigma2)\n",
    "\n",
    "n1 = 150\n",
    "n2 = 150\n",
    "sigma = 0.1\n",
    "X4, y4 = rand_checkers(n1, n2, sigma)\n",
    "\n",
    "############################################################################\n",
    "#     Displaying labeled data\n",
    "############################################################################\n",
    "\n",
    "# plt.show()\n",
    "plt.close(\"all\")\n",
    "# plt.ion()\n",
    "plt.figure(1, figsize=(15, 5))\n",
    "plt.subplot(141)\n",
    "plt.title('First data set')\n",
    "plot_2d(X1, y1)\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.title('Second data set')\n",
    "plot_2d(X2, y2)\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.title('Third data set')\n",
    "plot_2d(X3, y3)\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.title('Fourth data set')\n",
    "plot_2d(X4, y4)\n",
    "# plt.show(block=True)\n",
    "\n",
    "############################################################################\n",
    "#     K-NN\n",
    "############################################################################\n",
    "\n",
    "# Q2 : Write your own implementation\n",
    "print(\"*** Q2 ***\")\n",
    "\n",
    "\n",
    "class KNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Home made KNN Classifier class.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        # TODO: Compute all pairwise distances between X and self.X_ using e.g.\n",
    "        # metrics.pairwise.pairwise_distances\n",
    "        dist = metrics.pairwise.pairwise_distances(X, Y=self.X_, metric='minkowski', p=2)\n",
    "        # Get indices to sort them\n",
    "        idx_sort = np.argsort(dist, axis=1)\n",
    "        # Get indices of neighbors\n",
    "        idx_neighbors = idx_sort[:, :self.n_neighbors]\n",
    "        # Get labels of neighbors\n",
    "        y_neighbors = self.y_[idx_neighbors]\n",
    "        # Find the predicted labels y for each entry in X\n",
    "        # You can use the scipy.stats.mode function\n",
    "        mode, _ = stats.mode(y_neighbors, axis=1)\n",
    "        # the following might be needed for dimensionality\n",
    "        y_pred = np.asarray(mode.ravel(), dtype=np.intp)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# TODO : compare your implementation with scikit-learn\n",
    "\n",
    "# Focus on dataset 2 for instance\n",
    "X_train = X2[::2]\n",
    "Y_train = y2[::2].astype(int)\n",
    "X_test = X2[1::2]\n",
    "Y_test = y2[1::2].astype(int)\n",
    "\n",
    "homemade_knn = KNNClassifier(n_neighbors=5)\n",
    "homemade_knn.fit(X_train, Y_train)\n",
    "homemade_pred = homemade_knn.predict(X_test)\n",
    "\n",
    "sklearn_knn = neighbors.KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "sklearn_knn.fit(X_train, Y_train)\n",
    "sklearn_pred = sklearn_knn.predict(X_test)\n",
    "\n",
    "print(\"Compare results Homemade / Sklearn : \", np.allclose(homemade_pred, sklearn_pred))\n",
    "\n",
    "# TODO: use KNeighborsClassifier vs. KNNClassifier\n",
    "\n",
    "\n",
    "# Q3 : test now all datasets\n",
    "# From now on use the Scikit-Learn implementation\n",
    "\n",
    "print(\"*** Q3 ***\")\n",
    "n_neighbors = 5  # the k in k-NN\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "for X, y in [(X1, y1), (X2, y2), (X3, y3), (X4, y4)]:\n",
    "    def f(xx):\n",
    "        \"\"\"Classifier: needed to avoid warning due to shape issues.\"\"\"\n",
    "        return knn.predict(xx.reshape(1, -1))\n",
    "\n",
    "\n",
    "    knn.fit(X, y)\n",
    "    plt.figure()\n",
    "    plot_2d(X, y)\n",
    "    n_labels = np.unique(y).shape[0]\n",
    "    frontiere_new(f, X, y, w=None, step=50, alpha_choice=1, n_labels=n_labels,\n",
    "                  n_neighbors=n_neighbors)\n",
    "    # plt.show(block=True)\n",
    "\n",
    "# Q4: Display the result when varying the value of K\n",
    "\n",
    "print(\"*** Q4 ***\")\n",
    "plt.figure(3, figsize=(12, 8))\n",
    "plt.subplot(3, 5, 3)\n",
    "plot_2d(X_train, Y_train)\n",
    "plt.xlabel('Samples')\n",
    "ax = plt.gca()\n",
    "ax.get_yaxis().set_ticks([])\n",
    "ax.get_xaxis().set_ticks([])\n",
    "\n",
    "for n in range(1, 11):\n",
    "    # TODO : fit the knn\n",
    "    knn_n = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
    "    knn_n.fit(X_train, Y_train)\n",
    "    plt.subplot(3, 5, 5 + n)\n",
    "    plt.xlabel('KNN with k=%d' % n)\n",
    "\n",
    "\n",
    "    def f(xx):\n",
    "        \"\"\"Classifier: needed to avoid warning due to shape issues.\"\"\"\n",
    "        return knn_n.predict(xx.reshape(1, -1))\n",
    "\n",
    "\n",
    "    n_labels = np.unique(Y_train).shape[0]\n",
    "    frontiere_new(f, X_train, Y_train, w=None, step=50, alpha_choice=1, n_labels=n_labels,\n",
    "                  colorbar=False, samples=False, n_neighbors=n)\n",
    "    plt.draw()  # update plot\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# plt.show(block=True)\n",
    "\n",
    "\n",
    "def f(xx):\n",
    "    \"\"\"Classifier: needed to avoid warning due to shape issues\"\"\"\n",
    "    return knn.predict(xx.reshape(1, -1))\n",
    "\n",
    "\n",
    "frontiere_new(f, X_train, Y_train, w=None, step=50, alpha_choice=1)\n",
    "# plt.show(block=True)\n",
    "print(knn.predict(X_train))\n",
    "\n",
    "# Q5 : Scores on train data\n",
    "print(\"*** Q5 ***\")\n",
    "\n",
    "\n",
    "# TODO\n",
    "def compute_err(y_pred, y):\n",
    "    tau_err = float(np.sum(y_pred != y)) / float(len(y))\n",
    "    tau = 1 - tau_err\n",
    "    return tau\n",
    "\n",
    "\n",
    "knn_1 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn_1.fit(X_train, Y_train)\n",
    "print(\"Compute error in training : \", knn_1.score(X_train, Y_train))\n",
    "print(\"Compute error in test : \", knn_1.score(X_test, Y_test))\n",
    "\n",
    "# Q6 : Scores on left out data\n",
    "print(\"*** Q6 ***\")\n",
    "\n",
    "n1 = n2 = 200\n",
    "sigma = 0.1\n",
    "data4 = rand_checkers(2 * n1, 2 * n2, sigma)\n",
    "\n",
    "X_train = X4[::2]\n",
    "Y_train = y4[::2].astype(int)\n",
    "X_test = X4[1::2]\n",
    "Y_test = y4[1::2].astype(int)\n",
    "\n",
    "# TODO\n",
    "plt.figure()\n",
    "for n0 in [200, 500, 1000]:\n",
    "    n1 = n2 = n0\n",
    "    sigma = 0.1\n",
    "    X_data4, Y_data4 = rand_checkers(2 * n1, 2 * n2, sigma)\n",
    "\n",
    "    X_train = X_data4[::2]\n",
    "    Y_train = Y_data4[::2].astype(int)\n",
    "    X_test = X_data4[1::2]\n",
    "    Y_test = Y_data4[1::2].astype(int)\n",
    "\n",
    "    error_curve = ErrorCurve(k_range=list(range(1, 200)))\n",
    "    error_curve.fit_curve(X_train, Y_train, X_test, Y_test)\n",
    "    error_curve.plot(maketitle=False)\n",
    "\n",
    "############################################################################\n",
    "#     Digits data\n",
    "############################################################################\n",
    "\n",
    "# Q8 : test k-NN on digits dataset\n",
    "print(\"*** Q8 ***\")\n",
    "\n",
    "# The digits dataset:\n",
    "# from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "print(type(digits))\n",
    "# A Bunch is a subclass of 'dict' (dictionary)\n",
    "# help(dict)\n",
    "# see also \"http://docs.python.org/2/library/stdtypes.html#mapping-types-dict\"\n",
    "\n",
    "plt.close(7)\n",
    "plt.figure(7)\n",
    "for index, (img, label) in enumerate(list(zip(digits.images, digits.target))[10:20]):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=plt.cm.gray_r, interpolation='None')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(digits.target, normed=True)\n",
    "plt.title(\"Digits histogram over the whole dataset\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "n_samples = len(digits.data)\n",
    "\n",
    "X_train = digits.data[:n_samples // 2]\n",
    "Y_train = digits.target[:n_samples // 2]\n",
    "X_test = digits.data[n_samples // 2:]\n",
    "Y_test = digits.target[n_samples // 2:]\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "score = knn.score(X_test, Y_test)\n",
    "print('Score : %s' % score)\n",
    "\n",
    "# Q9 : Compute confusion matrix\n",
    "print(\"*** Q9 ***\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "# TODO : compute and show confusion matrix\n",
    "conf_mat = confusion_matrix(Y_test, Y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "# Q10 : Estimate k with cross-validation for instance\n",
    "\n",
    "# Have a look at the class  'LOOCurve', defined in the source file.\n",
    "# from tp_knn_source import LOOCurve\n",
    "\n",
    "loo_curve = LOOCurve(k_range=list(range(1, 50, 5)) + list(range(100, 300, 100)))\n",
    "\n",
    "# TODO\n",
    "plt.figure()\n",
    "loo_curve.fit_curve(X_train, Y_train)\n",
    "loo_curve.plot(maketitle=False)\n",
    "\n",
    "\n",
    "# # Q11: Weighted k-NN\n",
    "#\n",
    "#\n",
    "# def weights(dist, h=0.1):\n",
    "#     \"\"\"Return array of weights, exponentially small w.r.t. the distance.\n",
    "#\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dist : a one-dimensional array of distances.\n",
    "#\n",
    "#     Returns\n",
    "#     -------\n",
    "#     weight : array of the same size as dist\n",
    "#     \"\"\"\n",
    "#\n",
    "#     return  # TODO\n",
    "#\n",
    "#\n",
    "# n_neighbors = 5\n",
    "# wknn = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors,\n",
    "#                                       weights=partial(weights, h=0.01))\n",
    "# wknn.fit(X_train, Y_train)\n",
    "#\n",
    "#\n",
    "# def f(xx):\n",
    "#     \"\"\"Classifier: needed to avoid warning due to shape issues.\"\"\"\n",
    "#     return wknn.predict(xx.reshape(1, -1))\n",
    "#\n",
    "# plt.figure(5)\n",
    "# plot_2d(X_train, Y_train)\n",
    "# frontiere_new(f, X_train, Y_train, w=None, step=50, alpha_choice=1)\n",
    "\n",
    "plt.show(block=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
